# GAE-based_Model_Poisoning_Attack_FL
These codes are about graph autoencoder-based model poisoning attack against federated learning.

K. Li, J. Zheng, X. Yuan, W. Ni, O. B. Akan and H. V. Poor, "Data-Agnostic Model Poisoning Against Federated Learning: A Graph Autoencoder Approach," in IEEE Transactions on Information Forensics and Security, vol. 19, pp. 3465-3480, 2024, doi: 10.1109/TIFS.2024.3362147. keywords: {Data models;Computational modeling;Training;Servers;Correlation;Wireless communication;Security;Federated learning;model poisoning attack;graph autoencoder;feature correlation}. The more details can be found [here](https://ieeexplore.ieee.org/document/10419367)

## Requirements
- Install requirements via  `pip install -r requirements.txt`


## How to run :point_down:
```
python FL_SVM_GAE_Attack_Device_Side.py 
```


## References
1. https://github.com/aswarth123/Federated_Learning_MNIST
2. https://github.com/zfjsail/gae-pytorch


